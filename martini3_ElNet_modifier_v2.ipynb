{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a98d9cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:49:31.656797Z",
     "start_time": "2022-11-02T11:49:29.880902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following elastic network removals were requested:\n",
      "All: ['R:266:279']\n",
      "Following elastic network additions were requested:\n",
      "Single: ['A:280:433,dis:0.95,fc:700']\n",
      "Automatic: ['A:50:75,eu:0.85,el:0.5,fc:700,replace']\n",
      "Processing itp file\n",
      "Creating elastic network removal list\n",
      "Removal list calculated\n",
      "Will look for 13118 Potential elastic network bonds\n",
      "60 elastic network bonds were removed\n",
      "A:280:433\n",
      "dis:0.95\n",
      "fc:700\n",
      "-as A:280:433,dis:0.95,fc:700 relating to atom 607 and 960\n",
      "\n",
      "Checking for existing bond to be replaced for -as A:280:433,dis:0.95,fc:700\n",
      "\n",
      "No existing bond found. Creating a new one.\n",
      "\n",
      "{'A': ['280', '433'], 'dis': '0.95', 'fc': '700'}\n",
      "\n",
      "\n",
      "File martini3_ElNet_modifier_test_files/AtSUC1_res152_standard_modified.itp already exists. Backing it up\n",
      "Writing output file: martini3_ElNet_modifier_test_files/AtSUC1_res152_standard_modified.itp\n",
      "File martini3_ElNet_modifier_test_files/test.log already exists. Backing it up\n",
      "Writing log file: martini3_ElNet_modifier_test_files/AtSUC1_res152_standard_modified.itp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %reset -f\n",
    "\n",
    "'''\n",
    "This python script modifies the elastic network in a supplied itp file\n",
    "Input:\n",
    "-i [required] Name of input itp file.\n",
    "-o [optional] Name of output itp file.\n",
    "-l [optional] Name of output log file containing removed elastic network lines. A log file will not be created unless a name has been given.\n",
    "------------\n",
    "At least one of the following commands must be used before the script will run.\n",
    "For the following commands: All residus mentioned by the commands are included in the selection.\n",
    "------------\n",
    "-ri [optional] Remove internal elastic networks. Examples:\n",
    "    -ri R:245:282\" Removes all elastic networks between all residues from residue 245 to residue 282.\n",
    "    -ri R:245:282-E:266:279 Same as above except residue 266 to 279 are exempt from the selection.\n",
    "\n",
    "-re [optional] Remove external elastic networks. Examples:\n",
    "    -re R:245:282 Removes all elastic networks between any residue from 245 to 282 and all other residues.\n",
    "    -re R:245:282-E:266:279 Same as above except residue 266 to 279 are exempt from the selection.\n",
    "    -re R:245:282-E:400:450 Same as first example except residue 400 to 450 are exempt from the non-selected residues.\n",
    "\n",
    "-rb [optional] Remove elastic networks between two groups of residues. Examples:\n",
    "    -rb R:30:244,R:283:500 Removes all elastic network between the two groups of residues.\n",
    "    (group 1: 30 to 244 and group 2: 283 to 500)\n",
    "    -rb R:30:244,R:283:500-E:350:400 Removes all elastic network between the two groups of residues.\n",
    "    (group 1: 30 to 244 and group 2: 283 to 349 and 401 to 500)\n",
    "'''\n",
    "\n",
    "import os.path\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "# import scipy as spy\n",
    "from scipy.spatial import distance\n",
    "\n",
    "### Parser\n",
    "# parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# ### Optional arguments\n",
    "# parser.add_argument(\"-o\", dest = \"output_name\", default = None,\n",
    "#                     help = \"Name of output itp file.\")\n",
    "\n",
    "# parser.add_argument(\"-l\", dest = \"log_name\", default = None,\n",
    "#                     help = \"Name of output log file containing removed elastic network lines.\\n\"\n",
    "#                     \"A log file will not be created unless a name has been given.\\n\")\n",
    "\n",
    "# ### Remove networks flags\n",
    "# # Remove internal networks\n",
    "# parser.add_argument('-ri', dest = \"remove_internal\", action='append', default = [], nargs='+',\n",
    "#                     help = \"Removes internal elastic networks. Examples:\\n\"\n",
    "#                     \"-ri R:245:282 Removes all elastic networks between all residues from residue 245 to residue 282.\\n\"\n",
    "#                     \"-ri R:245:282-E:266:279 Same as above except residue 266 to 279 are exempt from the selection.\\n\")\n",
    "\n",
    "# # Remove external networks\n",
    "# parser.add_argument('-re', dest = \"remove_external\", action='append', default = [], nargs='+',\n",
    "#                     help = \"Removes external elastic networks. Examples:\\n\"\n",
    "#                     \"-re R:266:279 Removes all elastic networks between any residue from 266 to 279 and all other residues.\\n\"\n",
    "#                     \"-re R:266:279-E:270:275 Same as above except residue 270 to 275 are exempt from the selection.\\n\"\n",
    "#                     \"-re R:266:279-E:400:450 Same as first example except residue 400 to 450 are exempt from the non-selected residues.\\n\")\n",
    "\n",
    "# # Remove networks between two groups\n",
    "# parser.add_argument('-rb', dest = \"remove_between\", action='append', default = [], nargs='+',\n",
    "#                     help = \"Removes elastic networks between two groups of residues. Examples:\\n\"\n",
    "#                     \"-rb R:30:244,R:283:500 Removes all elastic network between the two groups of residues.\\n\"\n",
    "#                     \"(group 1: 30 to 244 and group 2: 283 to 500)\\n\"\n",
    "#                     \"-rb R:30:244-E40:50,R:283:500-E:350:400 Removes all elastic network between the two groups of residues.\\n\"\n",
    "#                     \"(group 1: 30 to 39 and 41 to 244 and group 2: 283 to 349 and 401 to 500)\\n\")\n",
    "\n",
    "# # Remove all networks associated with this residue selection\n",
    "# parser.add_argument('-ra', dest = \"remove_all\", action='append', default = [], nargs='+',\n",
    "#                     help = \"Removes all elastic networks associated with this selection.\\n\")\n",
    "\n",
    "########################################## NOT IMPLEMENTED\n",
    "### # ### Modify networks\n",
    "### # # Modify Fc and/or distance\n",
    "### # parser.add_argument('-ms', dest = \"modify_single\", action='append', default = [], nargs='+',\n",
    "### #                     help = \"Add elastic networks between two groups of residues. Examples:\\n\"\n",
    "### #                     \"-as M:280:433,dis:0.95,fc:700 Changes the Fc and distance networks between the two residues.\\n\"\n",
    "### #                     \"dis designates the distance for the bond. If not distance given, then it will be\"\n",
    "### #                     \"calculated based on pdb file. fc designates the force constant of the bond\\n\")\n",
    "\n",
    "### # Modify multiple\n",
    "### # parser.add_argument('-mm', dest = \"modify_multiple\", action='append', default = [], nargs='+',\n",
    "### #                     help = \"Add elastic networks between two groups of residues. Examples:\\n\"\n",
    "### #                     \"-as M:280:433,dis:0.95,fc:700 Changes the Fc and distance networks between the two residues.\\n\"\n",
    "### #                     \"dis designates the distance for the bond. If not distance given, then it will be\"\n",
    "### #                     \"calculated based on pdb file. fc designates the force constant of the bond\\n\")\n",
    "##########################################\n",
    "\n",
    "# ### Add networks\n",
    "# # Input pdb file\n",
    "# parser.add_argument('-f', dest = \"struc_name\", default = None,\n",
    "#                     help = \"A pdb or gro file is required to add networks based on pre-existing distances\\n\"\n",
    "#                      \"Protein must not stretch across the periodic boundary\\n\")\n",
    "\n",
    "# # Add a single bond between two residues\n",
    "# parser.add_argument('-as', dest = \"add_single\", action='append', default = [], nargs='+',\n",
    "#                     help = \"Add elastic networks between two groups of residues. Examples:\\n\"\n",
    "#                     \"-as A:280:433,dis:0.95,fc:700 Adds elastic networks between the two residues.\\n\"\n",
    "#                     \"dis designates the distance for the bond. If no distance is given, then it will be\"\n",
    "#                     \"calculated based on pdb file. fc designates the force constant of the bond (default = 700)\\n\")\n",
    "\n",
    "# # Generate elastic network for range of residues (between selection and whole itp)\n",
    "# parser.add_argument('-aa', dest = \"add_automatic\", action='append', default = [], nargs='+',\n",
    "#                     help = \"Add elastic networks between two groups of residues. Examples:\\n\"\n",
    "#                     \"Requires pdb file. Distances will be based on said pdb file.\\n\"\n",
    "#                     \"-aa A:50:75,eu:0.85,el:0.5,fc:700,replace\\n\"\n",
    "#                     \"Generates elastic networks for all of the residues in the selection.\\n\"\n",
    "#                     \"eu, el and fc sets the upper limit, lower limit and force constant.\\n\"\n",
    "#                     \"replace designates that existing networks should be replaced instead of skipped.\\n\")\n",
    "\n",
    "# ### Arguments required for script to run\n",
    "# requiredNamed = parser.add_argument_group('required arguments')\n",
    "# requiredNamed.add_argument('-i', dest = \"input_name\",\n",
    "#                            help = \"Name of input itp file.\", required = True)\n",
    "\n",
    "# ### Print parser help if no flags provided:\n",
    "# if len(sys.argv) == 1:\n",
    "#     parser.print_help()\n",
    "#     sys.exit()\n",
    "\n",
    "# ### Parses the arguments (checks if required arguments are present)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# ### Input file naming\n",
    "# input_name = args.input_name\n",
    "\n",
    "# ### Networks to be removed:\n",
    "# rem_int_input = args.remove_internal\n",
    "# rem_ext_input = args.remove_external\n",
    "# rem_btw_input = args.remove_between\n",
    "# rem_all_input = args.remove_all\n",
    "\n",
    "# ### Networks to be added:\n",
    "# add_sin_input = args.add_single\n",
    "# add_aut_input = args.add_automatic\n",
    "\n",
    "# ### Output file naming\n",
    "# if args.output_name != None:\n",
    "#     output_name = args.output_name\n",
    "# else:\n",
    "#     output_name = input_name[:-4] + \"_modified\" + \".itp\"\n",
    "\n",
    "# ### structure file (pdb or gro)\n",
    "# if args.struc_name != None:\n",
    "#     struc_name = args.struc_name\n",
    "\n",
    "# ### Log file naming\n",
    "# log_file = []\n",
    "# log_file.extend(\"Output itp file: \" + output_name + \"\\n\")\n",
    "# create_log = False\n",
    "# if args.log_name != None:\n",
    "#     create_log = True\n",
    "#     log_name = args.log_name\n",
    "#     log_file.extend(\"Log file: \" + log_name + \"\\n\")\n",
    "\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### Parser Handling done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### Test files\n",
    "\n",
    "input_name = \"martini3_ElNet_modifier_test_files/AtSUC1_res152_standard.itp\"\n",
    "output_name = \"martini3_ElNet_modifier_test_files/AtSUC1_res152_standard_modified.itp\"\n",
    "struc_name = \"martini3_ElNet_modifier_test_files/04_output_martinize.pdb\"\n",
    "\n",
    "rem_int_input = [[]]\n",
    "rem_ext_input = [[]]\n",
    "rem_btw_input = [[]]\n",
    "rem_all_input = [[]]\n",
    "\n",
    "add_sin_input = [[]]\n",
    "add_aut_input = [[]]\n",
    "\n",
    "# rem_int_input = [[\"R:245:282-E:266:279\"]]\n",
    "# rem_ext_input = [[\"R:245:282\"], [\"R:463:471\"]]\n",
    "# rem_ext_input = [[\"R:266:279\"]]\n",
    "# rem_btw_input = [[\"R:30:244,R:283:500\"]]\n",
    "rem_all_input = [[\"R:266:279\"]]\n",
    "\n",
    "add_sin_input = [[\"A:280:433,dis:0.95,fc:700\"]]\n",
    "add_aut_input = [[\"A:50:75,eu:0.85,el:0.5,fc:700,replace\"]]\n",
    "\n",
    "log_file = []\n",
    "create_log = True\n",
    "log_name = \"martini3_ElNet_modifier_test_files/test.log\"\n",
    "log_file.extend(\"Log file: \" + log_name + \"\\n\")\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### Test files over\n",
    "\n",
    "print(\"Following elastic network removals were requested:\")\n",
    "if rem_int_input != [[]]:\n",
    "    for i in rem_int_input:\n",
    "        print(\"Internal: \" + str(i))\n",
    "\n",
    "if rem_ext_input != [[]]:\n",
    "    for i in rem_ext_input:\n",
    "        print(\"External: \" + str(i))\n",
    "\n",
    "if rem_btw_input != [[]]:\n",
    "    for i in rem_btw_input:\n",
    "        print(\"Between: \" + str(i))\n",
    "\n",
    "if rem_all_input != [[]]:\n",
    "    for i in rem_all_input:\n",
    "        if rem_int_input == [[]]:\n",
    "            rem_int_input = rem_all_input\n",
    "        else:\n",
    "            rem_int_input.append(i)\n",
    "        if rem_ext_input == [[]]:\n",
    "            rem_ext_input = rem_all_input\n",
    "        else:\n",
    "            rem_ext_input.append(i)\n",
    "        print(\"All: \" + str(i))\n",
    "\n",
    "print(\"Following elastic network additions were requested:\")\n",
    "if add_sin_input != [[]]:\n",
    "    for i in add_sin_input:\n",
    "        print(\"Single: \" + str(i))\n",
    "\n",
    "if add_aut_input != [[]]:\n",
    "    for i in add_aut_input:\n",
    "        print(\"Automatic: \" + str(i))\n",
    "\n",
    "### Open files\n",
    "def file_reader(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    file_read = [i for i in file]\n",
    "    file.close()\n",
    "    return file_read\n",
    "itp_file = file_reader(input_name)\n",
    "\n",
    "### Finds the appropriate lines for ElNet modifications\n",
    "itp_separators_dict = {}\n",
    "atom_line_found = False\n",
    "ElNet_line_found = False\n",
    "print(\"Processing itp file\")\n",
    "for line_number, line in enumerate(itp_file):\n",
    "    ### [:-1] is to remove the \\n from all lines\n",
    "    if \"[ atoms ]\" in line[:-1]:\n",
    "        itp_separators_dict[\"atoms_start\"] = line_number + 1\n",
    "        atom_line_found = True\n",
    "    if atom_line_found == True and line[:-1] == \"\":\n",
    "        itp_separators_dict[\"atoms_end\"] = line_number\n",
    "        atom_line_found = False\n",
    "    \n",
    "    if \"Rubber band\" in line[:-1]:\n",
    "        itp_separators_dict[\"ElNet_start\"] = line_number + 1\n",
    "        ElNet_line_found = True\n",
    "    if ElNet_line_found == True and line[:-1] == \"\":\n",
    "        itp_separators_dict[\"ElNet_end\"] = line_number\n",
    "        ElNet_line_found = False\n",
    "\n",
    "itp_separators_sorted_list = sorted([(name, line_nr) for name, line_nr in itp_separators_dict.items()], key=lambda x: x[1])\n",
    "\n",
    "### Creates dictionary of residues and atoms from itp file\n",
    "residue_dict = {}\n",
    "list_of_atom_numbers = []\n",
    "\n",
    "for atom in itp_file[itp_separators_dict[\"atoms_start\"]:itp_separators_dict[\"atoms_end\"]]:\n",
    "    atom_split = atom.split()\n",
    "    if str(atom_split[2]) not in residue_dict.keys() and \"BB\" in atom_split:\n",
    "        residue_dict[str(atom_split[2])] = [atom_split[0]]\n",
    "        list_of_atom_numbers.append(atom_split[0])\n",
    "    elif str(atom_split[2]) in residue_dict.keys() and \"BB\" in atom_split:\n",
    "        residue_dict[str(atom_split[2])].append(atom_split[0])\n",
    "        list_of_atom_numbers.append(atom_split[0])\n",
    "\n",
    "### Creates list of existing ElNets\n",
    "ElNets = itp_file[itp_separators_dict[\"ElNet_start\"]:itp_separators_dict[\"ElNet_end\"]]\n",
    "\n",
    "\n",
    "### Creates list of coordinates for each atom if structure file is present and array of distances between atoms\n",
    "if struc_name != None:\n",
    "    struc_file = file_reader(struc_name)\n",
    "    ### If pdb file\n",
    "    if struc_name[-3:] == \"pdb\":\n",
    "        struc_file_split = [(line.split()[5], line.split()[1], line.split()[6], line.split()[7], line.split()[8]) for line in struc_file\n",
    "                           if line.split()[0] == \"ATOM\"\n",
    "                           and line.split()[1] in residue_dict[line.split()[5]]] ### Bead (atom) in residue dict\n",
    "    ### If gro file\n",
    "    if struc_name[-3:] == \"gro\":\n",
    "        struc_file_split = [(line.split()[2], ''.join(filter(str.isdigit, line.split()[0])), line.split()[3], line.split()[4], line.split()[5]) for line in struc_file\n",
    "                           if len(line) == 6 ### Correct length\n",
    "                           and any([line.split()[1][:2] == \"BB\", line.split()[1][:2] == \"SC\"]) ### Checks if bead\n",
    "                           and ''.join(filter(str.isdigit, line.split()[0])) in residue_dict[''.join(filter(str.isdigit, line.split()[0]))]] ### Bead (atom) in residue dict\n",
    "    \n",
    "    coordinates_list = [(float(x) * 0.1, float(y) * 0.1, float(z) * 0.1) for resid, atom, x, y, z in struc_file_split]\n",
    "    \n",
    "    distances_array = distance.cdist(coordinates_list, coordinates_list, \"euclidean\")\n",
    "    distances_dict = {}\n",
    "    for i in range(len(distances_array)):\n",
    "        for j in range(len(distances_array)):\n",
    "            if abs(int(i) - int(j)) > 2:\n",
    "                distances_dict[(str(list_of_atom_numbers[i]), str(list_of_atom_numbers[j]))] = str(round(distances_array[i, j], 5))\n",
    "\n",
    "### ### ### ### Functions\n",
    "### Removes exemptions from atom list\n",
    "def exemptions_remover(ElNet_list, exemptions):\n",
    "    ### Finds all the atoms that are exempt from the selection\n",
    "    exemptions_list = []\n",
    "    for exemption in exemptions:\n",
    "        rem_type, start_res, end_res = exemption.split(\":\")\n",
    "        atom_exempt_list = [atom for res in range(int(start_res), int(end_res) + 1) for atom in residue_dict[str(res)]]\n",
    "        exemptions_list.extend(atom_exempt_list)\n",
    "\n",
    "    ### Removes exempt atoms from selection\n",
    "    for atom_ex in exemptions_list:\n",
    "        if atom_ex in ElNet_list:\n",
    "            ElNet_list.remove(atom_ex)\n",
    "    \n",
    "    return ElNet_list\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### Removals\n",
    "### ### List containing all networks to be removed\n",
    "print(\"Creating elastic network removal list\")\n",
    "Main_remover_list = []\n",
    "\n",
    "### ### Writing requested changes to log file\n",
    "log_requested_removals = []\n",
    "\n",
    "### ### ### Internal elastic network removal calculator:\n",
    "if rem_int_input != [[]]:\n",
    "    for internal in rem_int_input:\n",
    "        exemptions_present = False\n",
    "        input_split = internal[0].split(\"-\")\n",
    "        \n",
    "        log_requested_removals.append(\"-ri \" + internal[0] + \"\\n\")\n",
    "\n",
    "        remove_list = input_split[0]\n",
    "        if len(input_split) > 1:\n",
    "            exemptions = input_split[1:]\n",
    "            exemptions_present = True\n",
    "\n",
    "        rem_type, start_res, end_res = remove_list.split(\":\")\n",
    "\n",
    "        ### Finds all the atoms in the removal selection \n",
    "        atom_list = [str(atom) for res in range(int(start_res), int(end_res) + 1) for atom in residue_dict[str(res)]]\n",
    "\n",
    "        ### Finds all the atoms that are exempt from the selection\n",
    "        if exemptions_present == True:\n",
    "            atom_list = exemptions_remover(ElNet_list = atom_list, exemptions = exemptions)\n",
    "\n",
    "        Main_remover_list.extend([(atom_1, atom_2) for atom_1 in atom_list for atom_2 in atom_list if atom_1 != atom_2])\n",
    "\n",
    "### ### ### External elastic network removal calculator:\n",
    "if rem_ext_input != [[]]:\n",
    "    for external in rem_ext_input:\n",
    "        exemptions_present = False\n",
    "        input_split = external[0].split(\"-\")\n",
    "        \n",
    "        log_requested_removals.append(\"-re \" + external[0] + \"\\n\")\n",
    "        \n",
    "        remove_list = input_split[0]\n",
    "        if len(input_split) > 1:\n",
    "            exemptions = input_split[1:]\n",
    "            exemptions_present = True\n",
    "\n",
    "        rem_type, start_res, end_res = remove_list.split(\":\")\n",
    "\n",
    "        ### Finds all the atoms in the selection\n",
    "        atom_list = [str(atom) for res in range(int(start_res), int(end_res) + 1) for atom in residue_dict[str(res)]]\n",
    "\n",
    "        ### Finds all atoms not in selection\n",
    "        atom_ext_list = [str(atom) for res in list(residue_dict.keys()) for atom in residue_dict[str(res)] if atom not in atom_list]\n",
    "        \n",
    "        ### Finds all the atoms that are exempt from the selection\n",
    "        if exemptions_present == True:\n",
    "            atom_list = exemptions_remover(ElNet_list = atom_list, exemptions = exemptions)\n",
    "            atom_ext_list = exemptions_remover(ElNet_list = atom_ext_list, exemptions = exemptions)\n",
    "                \n",
    "        Main_remover_list.extend([(atom_1, atom_2) for atom_1 in atom_list for atom_2 in atom_ext_list if atom_1 != atom_2])\n",
    "        Main_remover_list.extend([(atom_1, atom_2) for atom_1 in atom_ext_list for atom_2 in atom_list if atom_1 != atom_2])\n",
    "\n",
    "### ### ### Between groups elastic network removal calculator:\n",
    "if rem_btw_input != [[]]:\n",
    "    for between in rem_btw_input:\n",
    "        group_atom_lists = []\n",
    "        \n",
    "        log_requested_removals.append(\"-rb \" + between[0] + \"\\n\")\n",
    "        \n",
    "        groups = [[group] for group in between[0].split(\",\")]\n",
    "        for group in groups:\n",
    "            exemptions_present = False\n",
    "            input_split = group[0].split(\"-\")\n",
    "\n",
    "            remove_list = input_split[0]\n",
    "            if len(input_split) > 1:\n",
    "                exemptions = input_split[1:]\n",
    "                exemptions_present = True\n",
    "\n",
    "            rem_type, start_res, end_res = remove_list.split(\":\")\n",
    "\n",
    "            ### Finds all the atoms in the selection\n",
    "            atom_list = [str(atom) for res in range(int(start_res), int(end_res) + 1) for atom in residue_dict[str(res)]]\n",
    "\n",
    "            ### Finds all the atoms that are exempt from the selection and non-selection\n",
    "            if exemptions_present == True:\n",
    "                atom_list = exemptions_remover(ElNet_list = atom_list, exemptions = exemptions)\n",
    "\n",
    "            group_atom_lists.append(atom_list)\n",
    "\n",
    "        Main_remover_list.extend([(atom_1, atom_2) for atom_1 in group_atom_lists[0] for atom_2 in group_atom_lists[1] if atom_1 != atom_2])\n",
    "        Main_remover_list.extend([(atom_1, atom_2) for atom_1 in group_atom_lists[1] for atom_2 in group_atom_lists[0] if atom_1 != atom_2])\n",
    "\n",
    "### Checks if removals have been requested\n",
    "if len(Main_remover_list) != 0:\n",
    "\n",
    "    print(\"Removal list calculated\")\n",
    "    ### Removes duplicates from list\n",
    "    len_MRL_before = len(Main_remover_list)\n",
    "    Main_remover_list = list(dict.fromkeys(Main_remover_list))\n",
    "    len_MRL_after = len(Main_remover_list)\n",
    "\n",
    "    if len_MRL_before - len_MRL_after != 0:\n",
    "        print(\"Removed \" + str(len_MRL_before - len_MRL_after) + \" duplicate entries in the removal list\")\n",
    "    print(\"Will look for \" + str(len(Main_remover_list)) + \" Potential elastic network bonds\")\n",
    "\n",
    "    elastic_remove_counter = 0\n",
    "    log_removed_networks = []\n",
    "    for rubber_band in reversed(ElNets):\n",
    "        rbs = rubber_band.split()\n",
    "        if (rbs[0], rbs[1]) in Main_remover_list:\n",
    "            elastic_remove_counter += 1\n",
    "            ElNets.remove(rubber_band)\n",
    "            log_removed_networks.append(rubber_band)\n",
    "\n",
    "    print(str(elastic_remove_counter) + \" elastic network bonds were removed\")\n",
    "\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### Additions\n",
    "log_requested_additions = []\n",
    "log_notice_additions = []\n",
    "# if add_aut_input != [[]]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if add_sin_input != [[]]:\n",
    "    for single in add_sin_input:\n",
    "        \n",
    "        \n",
    "        single_dict = {}\n",
    "        \n",
    "        for command in single[0].split(\",\"):\n",
    "            print(command)\n",
    "            single_dict[command.split(\":\")[0]] = command.split(\":\")[1:]\n",
    "        \n",
    "        atom1, atom2 = residue_dict[single_dict[\"A\"][0]][0], residue_dict[single_dict[\"A\"][1]][0]\n",
    "        \n",
    "        log_requested_additions.append(\"-as \" + single[0] + \" relating to atom \" + str(atom1) + \" and \" + str(atom2) + \"\\n\")\n",
    "        print(log_requested_additions[-1])\n",
    "        \n",
    "        ### Distance\n",
    "        if not \"dis\" in single_dict.keys():\n",
    "            assert (atom1, atom2) in distances_dict, \\\n",
    "                \"Atom pair not found in distance dictionary. Are you sure they are more than 2 residues apart?\"\n",
    "            single_dict[\"dis\"] = distances_dict[(atom1, atom2)]\n",
    "            log_notice_additions.append(\"No distance given for \" + \"-as \" + single[0] + \". Setting it to \" + single_dict[\"dis\"] + \"\\n\")\n",
    "            print(log_notice_additions[-1])\n",
    "        else:\n",
    "            single_dict[\"dis\"] = single_dict[\"dis\"][0] ### Otherwise will be a list with one string\n",
    "        \n",
    "        ### Force constant\n",
    "        if not \"fc\" in single_dict.keys():\n",
    "            single_dict[\"fc\"] = \"700\"\n",
    "            log_notice_additions.append(\"No force constant given for \" + \"-as \" + single[0] + \". Setting it to \" + single_dict[\"fc\"] + \"\\n\")\n",
    "            print(log_notice_additions[-1])\n",
    "        else:\n",
    "            single_dict[\"fc\"] = single_dict[\"fc\"][0] ### Otherwise will be a list with one string\n",
    "        \n",
    "        ### Checking if bond already exists \n",
    "        log_notice_additions.append(\"Checking for existing bond to be replaced for \" + \"-as \" + single[0] + \"\\n\")\n",
    "        print(log_notice_additions[-1])\n",
    "        replaced_questionmark = False\n",
    "        for line, rubber_band in enumerate(ElNets):\n",
    "            rbs = rubber_band.split()\n",
    "            if (rbs[0], rbs[1]) == (atom1, atom2):\n",
    "                ElNets[line] = atom1 + \" \" + atom2 + \" \" + \"1\" + \" \" + single_dict[\"dis\"] + \" \" + single_dict[\"fc\"] + \".0\" + \"\\n\"\n",
    "                replaced_questionmark = True\n",
    "                log_notice_additions.append(\"Existing bond found. Replacing it.\\n\")\n",
    "                print(log_notice_additions[-1])\n",
    "                break\n",
    "        if replaced_questionmark == False:\n",
    "            ElNets.append(atom1 + \" \" + atom2 + \" \" + \"1\" + \" \" + single_dict[\"dis\"] + \" \" + single_dict[\"fc\"] + \".0\" + \"\\n\")\n",
    "            log_notice_additions.append(\"No existing bond found. Creating a new one.\\n\")\n",
    "            print(log_notice_additions[-1])\n",
    "        \n",
    "        print(single_dict)\n",
    "\n",
    "\n",
    "### ### ### Log writer\n",
    "log_file.extend(\"The following lines show the requested removals\\n\")\n",
    "log_file.extend(log_requested_removals)\n",
    "log_file.extend(\"The following lines show the requested additions and their notes\\n\")\n",
    "log_file.extend(log_requested_additions)\n",
    "log_file.extend(log_notice_additions)\n",
    "log_file.extend(str(elastic_remove_counter) + \" \" + \"elastic networks were removed\\n\")\n",
    "log_file.extend(\"The following lines show the removed elastic networks\\n\")\n",
    "log_file.extend(log_removed_networks)\n",
    "\n",
    "### ### ### Output file handling\n",
    "### Inserting new elastic network system file\n",
    "before = itp_file[:itp_separators_dict[\"ElNet_start\"]]\n",
    "after = itp_file[itp_separators_dict[\"ElNet_end\"]:]\n",
    "new_itp_file = before + ElNets + after\n",
    "\n",
    "### Checks if output file already exists and backs it up\n",
    "def backupper(output_file_name):\n",
    "    output_file_split = output_file_name.split(\"/\")\n",
    "    output_path = \"\"\n",
    "    output_name = output_file_split[-1]\n",
    "    if len(output_file_split) > 1:\n",
    "        for i in range(len(output_file_split) - 1):\n",
    "            output_path += output_file_split[i] + \"/\"\n",
    "    if os.path.exists(output_file_name):\n",
    "        print(\"File \" + output_file_name + \" already exists. Backing it up\")\n",
    "        number = 1\n",
    "        while True:\n",
    "            if os.path.exists(output_path + \"#\" + output_name + \".\" + str(number) + \"#\"):\n",
    "                number += 1\n",
    "            else:\n",
    "                os.rename(output_file_name, output_path + \"#\" + output_name + \".\" + str(number) + \"#\")\n",
    "                break\n",
    "\n",
    "print(\"\\n\")\n",
    "### Output itp file\n",
    "backupper(output_name)\n",
    "print(\"Writing output file: \" + output_name)\n",
    "new_file = open(output_name, \"w\")\n",
    "for line in new_itp_file:\n",
    "    new_file.write(line)\n",
    "new_file.close()\n",
    "\n",
    "### Output log file\n",
    "if create_log == True:\n",
    "    backupper(log_name)\n",
    "    print(\"Writing log file: \" + output_name)\n",
    "    new_file = open(log_name, \"w\")\n",
    "    for line in log_file:\n",
    "        new_file.write(line)\n",
    "    new_file.close()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47c161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93991b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "769ac7b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T11:45:42.910003Z",
     "start_time": "2022-11-02T11:45:42.888273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': ['280', '433'], 'dis': '0.95', 'fc': '700'}\n",
      "677 1008\n",
      "607\n",
      "['607']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(list_of_atom_numbers[\u001b[38;5;241m280\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m25\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(residue_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m280\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlist_of_atom_numbers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresidue_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m280\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(residue_dict))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(single_dict)\n",
    "print(atom1, atom2)\n",
    "print(list_of_atom_numbers[280 - 25])\n",
    "print(residue_dict[\"280\"])\n",
    "print(list_of_atom_numbers[int(residue_dict[\"280\"][0])])\n",
    "print(max(residue_dict))\n",
    "# print(list_of_atom_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb1fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f16dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7e177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2359d604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e34b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b809578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d55034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edfad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46cf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae2c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12b14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b416076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75418fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7dc5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a318fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad174556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1507d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c951c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043f330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6393d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b55915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edc6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e0c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1246314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
